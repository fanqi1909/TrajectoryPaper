\section{Optimization}
\label{sec:optimization}
In this section, we describe several optimizations to the star-partition and mining algorithm.
In addition, we also address some practical issues when deploying the SPM algorithm
to real MapReduce based systems.

%We have analyzed that the bottlenecks of Algorithm~\ref{algo:apriori_mining} 
%lies in two factors. The size of each $Sr_s$ and the size of candidates in each level of Apriori.
%In this section, we provide several optimizations to boost the bottlenecks.
%\subsection{Edge Reduction by Direction}
%The first spot for reducing the size of $Sr_s$ is to remove the replicated edges. As shown in Algorithm~\ref{algo:spm_overview}, each edge in the conceptual graph is replicated twice in generating the star-structure. The purpose of replication is to ensure the completeness of star partition. However, this replication can be avoided if we choose an appropriate way of partitioning. 
%
%We design the edge partitioning method by edge direction. Instead of building a conceptual graph that is undirected, we create the directed conceptual graph as follows: First, we assign each object a unique number. Then
%for a cluster $C_t$ in snapshot $S_t$, for any pair $(u,v) \in C_t$, an edge $e(u,v) = \{t\}$ is created if $u < v$. It is easy to see that the directed conceptual graph is a DAG. We then create each $Sr_u$ by including all the outgoing edges of $u$. By so doing, each edge is assigned to only one star, thus avoids the replications. We use the following theorem to ensure the completeness of the edge direction method.
%
%\begin{theorem}[Sound and Completeness of Edge Direction]
%Star partition with edge direction is sound and complete.
%\end{theorem}
%\begin{proof}
%It is notable that each star is a subset of original trajectories, thus the soundness is trivially true. For completeness, if $P$ is valid pattern, then let $s$ be the object of the smallest number in $P.O$, i.e., $s=\min_{o \in P.O}(o)$. Since $s$ is smallest and the all other objects in $P.O$ is connected with $s$. Therefore, $P.O \equiv Sr_s$, which indicates that $P.O$ is also a pattern in $Sr_s$.
%\end{proof}
%An example of edge direction is shown in Figure~\ref{fig:star_partition}. As shown,
%by adapting the direction method, half the size of $S_r$'s is reduced. This clearly brings efficiency in both shuffling and apriori mining.

\subsection{Edge Simplification}
Each edge $e(s,v)$ in $Sr_s$ contains a time sequence $ET$ 
which represents the co-occurrence of $s$ and $v$. We notice that the edge 
between $s$ and $t$ is not always necessary. For example, if an edge has a
cardinality less than $K$, it is unnecessary to include this edge to 
$Sr_s$ since it cannot contribute to any patterns.
This motivates us to simplify the edges in $Sr_s$ 
to boost the overall performance.

Our goal of edge simplification is to, given a time sequence $T$, find a subsequence
of $T' \subseteq T$, such that $T'$ is potentially conforms to $K,L,G$. And we
wish $|T'|$ to be as small as possible.  
We star-off by observing that for every time sequence $T$, $T$ can be 
divided into a set of maximally $G$-connected subsequences. Note that
a maximally $G$-connected subsequence can potentially contribute to
a pattern if it conforms to $K,L$.
Therefore, we are able to reduce $T$
to its maximally $G$-connected subseuqnces which conform to $K,L$.

To formally describe the idea, we define the a \emph{candidate sequence} as follows:

%\begin{definition}[Candidate Sequence]
%Given the pattern parameters: $K,L,G$, a sequence $T$ is 
%a \emph{partly candidate} sequence if exists one of its maximal $G$-connected
%subsequence $T'$ such that $T'$ confirms to $L,K$.
%\end{definition}

%For example, let $L = 2, K = 4, G = 2$, sequence $T_1=(1,2,4,5,6,9,10,11)$ 
%is a \emph{partly candidate sequence} since $T_1[1:5] = (1,2,4,5,6)$ is a valid
%pattern wrt. $L,K,G$. In contrast, $T_2=(1,2,5,6,7)$ is not a valid partly candidate sequence.
%
%Observing that only partly candidate sequence can be potentially contribute to a 
%pattern. Therefore, given an edge $e(s,t)=T \in Sr_s$, if $T$ is not a partly
%candidate sequence, it can be pruned from $Sr_s$. To efficiently
%test whether a given sequence is partly candidate, we define the \emph{Fully Candidate Sequence}:

\begin{definition}[Candidate Sequence]
Given the pattern parameters: $L,K,G$, a sequence $T$ is a \emph{Candidate Sequence} 
if for any of its maximal $G$-connected sequence $T'$, $T'$ conforms to $L,K$.
\end{definition}

For example, let $L = 2, K = 4, G = 2$, sequence $T_1=(1,2,4,5,6,9,10,11,13)$ is 
not a fully candidate sequence since one of its maximal $G$-connected sequence $(9,10,11)$
is not a partly candidate sequence. In contrast, sequence $T_2=(1,2,4,5,6)$ is 
a fully candidate sequence.

To reduce a sequence $T$ to a candidate sequence, we need to strip out its 
maximal $G$-connected subsequences which does not form to $K,L$. Such a reduction
takes two rounds scan of $T$ as shown in Algorithm~\ref{algo:simp_prune}. In the 
first round, the consecutive portions of $T$ with size less than $L$ are removed.
In the second round, the maximal $G$-connected sequences of size less than $K$ are
removed. Clearly the simplification algorithm runs in $O(|T|)$ time.
\begin{algorithm}
\caption{Edge Simplification}
\label{algo:simp_prune}
\begin{algorithmic}[1]
\Require $T$
\State{---Remove the consecutive portion with size less than $L$---}
\State $c \gets 0$
\For {$i \in (0,...,|T|)$}
	\If{$T[i] - T[i-1] != 1$} 
		\If{$i - c < L$} 
			\State $T$ remove $[c:i)$
		\EndIf
		\State $c \gets i$
	\EndIf
\EndFor
\State{---Remove the pseduo-consecutive portion with size less than $K$---}
\State $s\gets 1$, $c\gets 0$
\For{$i \in (0: |T|)$}
	\If{$T[i] - T[i-1] > G$}
		\If{$s < K$}   
			\State $T$ remove $[c:i)$
		\EndIf
		\State {$c \gets i$, $s \gets 1$}
	\Else
		\State $s++$
	\EndIf
\EndFor
\end{algorithmic}
\end{algorithm}

\begin{example}
Take $T_1=\{1,2,4,5,6,9,10,11,13\}$ as an example of edge simplification. Let $L = 2, K = 4, G = 2$.
In the first round of scan. $T_1$ reduces to $\{1,2,4,5,6,9,10,11\}$. The consecutive subsequence $\{13\}$
is removed by $L=2$. $T_1$ has two maximal $G$-consecutive subsequences, which 
are $\{1,2,4,5,6\}$ and $\{9,10,11\}$. Since $K=4$, $\{9,10,11\}$ is removed
from $T_1$ in the second round of scan. Therefore, $T_1$ is simplified to $\{1,2,4,5,6\}$.
\end{example}

%
%Based on the fully candidate sequence, we can reduce an sequence $T$ to a 
%fully candidate sequence by striping out its non-partly candidate maximal pseudo-consecutive 
%sequences. The reduction works as in Algorithm~\ref{algo:simp_prune}. It takes two
%rounds of scan of an input $T$. In the first round of scan,
%the consecutive portion of $T$ with size less than $L$ is removed.
%In the second round of scan, the pseudo-consecutive portion of $T$ with size less than $K$
%is removed. 


By leveraging the edge simplification technique, 
the size of the edges in $Sr_s$ can be greatly reduced. If
an edge cannot be reduced to a candidate sequence, then it is directly removed from $Sr_s$.
If an edge can be reduced to a candidate sequence, replacing itself 
by the candidate sequence results in a more compact storage.

%We use the following theorem to state the completeness and correctness of the 
%edge reduction algorithm.
%\begin{theorem}[Soundness and Completeness Edge Simplification]
%Star partition with edge simplification is sound and complete.
%\end{theorem}
%
%\begin{proof}
%Soundness of the star partition is not affected by edge simplification since each star is a subset of original trajectory. For completeness, notice that given a time sequence $T$, and any of its maximal $G$-connected subsequence $T'$, if $T'$ does not conform to $L,K$, then $T'$ cannot contribute to any patterns. 
%\end{proof}


\subsection{Candidate Pruning}
\subsubsection{Temporal monotonicity}
During the apriori phase, we repeatedly join candidate patterns in different levels to generate a larger set
of a patterns. We observe that traditional monotonic property of Apriori algorithms \textbf{does not}
hold in GCMP mining. That is given two candidate $P_1, P_2$, if $P_1.O \subset P_2.O$ and $P_1$ is not 
a valid pattern, then $P_2$ may or may not be a valid pattern. However, we notice that
we may form another monotonic property based on the \emph{candidate sequence} such that
the Apriori algorithm could still benefit.

The intuition is that if a candidate $P_1.T$ cannot be reduce to a \emph{candidate sequence}, then $P_1$ cannot 
be valid pattern. Furthermore, any candidate $P_2$, with $P_1.O \subset P_2.O$ cannot be a valid pattern.
This \emph{temporal monotonic property} 
is explicitly described as in the follow theorem:

\begin{theorem}[Temporal Monotonic Property of GCMP]
Given the temporal parameters $L,G,K$, for a candidate $c$ in Algorithm~\ref{algo:apriori_mining},
if $c.T$ cannot be reduced to a candidate sequence, then for any candidate $c'$ with $c.O \subset c'.O$, $c'$ can be pruned.
\end{theorem}
\begin{proof}
Let $c_1$, $c_2$ be two candidates with $c_1.O \subset c_2.O$. It is easy to see that $c_1.T \supseteq c_2.T$.
If $c_1.T$ cannot be reduced to a candidate sequence, then any subset of $c_1.T$ cannot
be reduced. It follows that $c_2.T$ cannot be reduced neither. Thus,
if $c_1.T$ cannot be reduced to a candidate sequence, $c_2$ can be pruned. 
\end{proof}

\subsubsection{Forward closure checking}

\begin{example}
We use Figure~\ref{fig:star_partition} (c) to demonstrate the candidate pruning. As shown, at the initial stage, $\{3,6:1,4\}$ is pruned, since $\{1,4\}$ is not a candidate sequence. By temporal monotonicity, candidates containing objects $\{3,6\}$ can all be pruned. Therefore, we are able to directly prune $\{3,4,6\}$, $\{3,5,6\}$ and $\{3,4,5,6\}$.
\end{example}
%
%With the help of the \emph{Monotonic Property}, the number of new candidates in each level is greatly reduced. We verify this in the experiment session as well.
\subsection{Load Balancing}

\subsection{Duplication Detection}

\subsection{Handling Overlapping Clusters}