\section{Response to Reviewer 1}

\emph{The main con that I've spotted is the fact that the algorithm might have been
more nicely framed also within the Spark environment by taking advantage of
the various possibilities offered by it (e.g. caching of RDDs)}

\response{
We agree with the reviewer that utilizing advanced Spark features
would benefit our solutions. Indeed, our SPARE algorithm has already taken advantages of the Spark-only features (i.e., caching of RDDs and DAG execution engine). As described in Section 5.3, our SPARE algorithm uses a run-time best-fit strategy to achieve load balance. Using the DAG execution engine, we are able to augment traditional Map-Reduce workflow to the Map-Planning-Reduce workflow. With the support of in-memory caching of RDDs,
the Map results need not to be recomputed after the planning phase. As the result shown in Figure 8,  SPARE with best-fit strategy saves 15\% total time as compared to the randomly partition strategy (i.e., SPARE-RD).  If without Spark's features, such an optimization would be hardly possible, but SPARE-RD is still more efficient than the baseline TRPM.

We do not consider utilizing other Spark extensions such as Spark-GraphX, Spark-Streaming and Spark-MLlib because these extensions, as their name suggest, are for different application scenarios.
} 

